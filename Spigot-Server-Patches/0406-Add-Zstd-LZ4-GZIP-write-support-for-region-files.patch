From f76810bbac58ab004a17095f61aba411cdcdc707 Mon Sep 17 00:00:00 2001
From: egg82 <eggys82@gmail.com>
Date: Fri, 26 Jul 2019 12:27:13 -0600
Subject: [PATCH] Add Zstd/LZ4/(GZIP write) support for region files

Zstd using zstd-jni: https://github.com/luben/zstd-jni
LZ4 using lz4-java: https://github.com/lz4/lz4-java
There's a new option in PaperConfig for this which defaults to false.
Since the patch hooks Mojang's versioning system for new compression methods, it
should be internally consistent, easily-updatable, and reversible with a force-upgrade.

This will likely conflict with plugins and programs expecting region files to be compressed using the current standard.

diff --git a/pom.xml b/pom.xml
index beda5dc8..0da5199b 100644
--- a/pom.xml
+++ b/pom.xml
@@ -106,6 +106,17 @@
             <version>5.1.47</version>
             <scope>runtime</scope>
         </dependency>
+        <!-- Paper - zstd/LZ4 for region files -->
+        <dependency>
+            <groupId>com.github.luben</groupId>
+            <artifactId>zstd-jni</artifactId>
+            <version>1.4.1-1</version>
+        </dependency>
+        <dependency>
+            <groupId>org.lz4</groupId>
+            <artifactId>lz4-java</artifactId>
+            <version>1.6.0</version>
+        </dependency>
         <!-- testing -->
         <dependency>
             <groupId>junit</groupId>
diff --git a/src/main/java/com/destroystokyo/paper/PaperConfig.java b/src/main/java/com/destroystokyo/paper/PaperConfig.java
index 5942c343..14aa99a3 100644
--- a/src/main/java/com/destroystokyo/paper/PaperConfig.java
+++ b/src/main/java/com/destroystokyo/paper/PaperConfig.java
@@ -388,4 +388,17 @@ public class PaperConfig {
         maxBookPageSize = getInt("settings.book-size.page-max", maxBookPageSize);
         maxBookTotalSizeMultiplier = getDouble("settings.book-size.total-multiplier", maxBookTotalSizeMultiplier);
     }
+
+    public static int compressionMethod = 2;
+    private static void compressionMethod() {
+        compressionMethod = getInt("settings.compression-method", 2);
+        if (compressionMethod < 1 || compressionMethod > 127 || (compressionMethod > 2 && compressionMethod < 126)) {
+            fatal("compression-method must be 1, 2, 126, or 127");
+        }
+    }
+
+    public static boolean zstdUseHighCompression = false;
+    private static void zstdUseHighCompression() {
+        zstdUseHighCompression = getBoolean("settings.zstd-use-high-compression", false);
+    }
 }
diff --git a/src/main/java/net/minecraft/server/RegionFile.java b/src/main/java/net/minecraft/server/RegionFile.java
index 41f1e15c..cbabd2f6 100644
--- a/src/main/java/net/minecraft/server/RegionFile.java
+++ b/src/main/java/net/minecraft/server/RegionFile.java
@@ -1,5 +1,6 @@
 package net.minecraft.server;
 
+import com.destroystokyo.paper.PaperConfig;
 import com.destroystokyo.paper.exception.ServerInternalException;
 import com.google.common.collect.Lists;
 import java.io.BufferedInputStream;
@@ -165,14 +166,82 @@ public class RegionFile implements AutoCloseable {
                         byte[] abyte;
 
                         if (b0 == 1) {
+                            System.out.println("[GZIP] Decompressing chunk at " + chunkcoordintpair.x + ", " + chunkcoordintpair.z);
+
                             abyte = new byte[l - 1];
                             this.b.read(abyte);
+
+                            if (PaperConfig.compressionMethod == 1) {
+                                byte[] buf = new byte[1024 * 64];
+                                long start = System.nanoTime();
+                                GZIPInputStream inTest = new GZIPInputStream(new ByteArrayInputStream(abyte));
+                                while (inTest.available() > 0) { inTest.read(buf); }
+                                inTest.close();
+                                long finish = System.nanoTime();
+
+                                System.out.println("Decompression time: " + ((finish - start) / 1_000L) + "us");
+                            }
+
                             return new DataInputStream(new BufferedInputStream(new GZIPInputStream(new ByteArrayInputStream(abyte))));
                         } else if (b0 == 2) {
+                            System.out.println("[zlib] Decompressing chunk at " + chunkcoordintpair.x + ", " + chunkcoordintpair.z);
+
                             abyte = new byte[l - 1];
                             this.b.read(abyte);
+
+                            if (PaperConfig.compressionMethod == 2) {
+                                byte[] buf = new byte[1024 * 64];
+                                long start = System.nanoTime();
+                                InflaterInputStream inTest = new InflaterInputStream(new ByteArrayInputStream(abyte));
+                                while (inTest.available() > 0) { inTest.read(buf); }
+                                inTest.close();
+                                long finish = System.nanoTime();
+
+                                System.out.println("Decompression time: " + ((finish - start) / 1_000L) + "us");
+                            }
+
                             return new DataInputStream(new BufferedInputStream(new InflaterInputStream(new ByteArrayInputStream(abyte))));
-                        } else {
+                        }
+                        // Paper start - new compression support
+                        else if (b0 == 126) {
+                            System.out.println("[LZ4] Decompressing chunk at " + chunkcoordintpair.x + ", " + chunkcoordintpair.z);
+
+                            abyte = new byte[l - 1];
+                            this.b.read(abyte);
+
+                            if (PaperConfig.compressionMethod == 126) {
+                                byte[] buf = new byte[1024 * 64];
+                                long start = System.nanoTime();
+                                net.jpountz.lz4.LZ4FrameInputStream inTest = new net.jpountz.lz4.LZ4FrameInputStream(new ByteArrayInputStream(abyte));
+                                while (inTest.available() > 0) { inTest.read(buf); }
+                                inTest.close();
+                                long finish = System.nanoTime();
+
+                                System.out.println("Decompression time: " + ((finish - start) / 1_000L) + "us");
+                            }
+
+                            return new DataInputStream(new BufferedInputStream(new net.jpountz.lz4.LZ4FrameInputStream(new ByteArrayInputStream(abyte))));
+                        } else if (b0 == 127) {
+                            System.out.println("[zstd] Decompressing chunk at " + chunkcoordintpair.x + ", " + chunkcoordintpair.z);
+
+                            abyte = new byte[l - 1];
+                            this.b.read(abyte);
+
+                            if (PaperConfig.compressionMethod == 127) {
+                                byte[] buf = new byte[1024 * 64];
+                                long start = System.nanoTime();
+                                com.github.luben.zstd.ZstdInputStream inTest = new com.github.luben.zstd.ZstdInputStream(new ByteArrayInputStream(abyte));
+                                while (inTest.available() > 0) { inTest.read(buf); }
+                                inTest.close();
+                                long finish = System.nanoTime();
+
+                                System.out.println("Decompression time: " + ((finish - start) / 1_000L) + "us");
+                            }
+
+                            return new DataInputStream(new BufferedInputStream(new com.github.luben.zstd.ZstdInputStream(new ByteArrayInputStream(abyte))));
+                        }
+                        // Paper end
+                        else {
                             return null;
                         }
                     }
@@ -302,7 +371,7 @@ public class RegionFile implements AutoCloseable {
     private void writeChunkData(final int sectorOffset, final byte[] data, final int dataLength) throws IOException { this.a(sectorOffset, data, dataLength); } // Paper - OBFHELPER
     private void a(int i, byte[] abyte, int j) throws IOException {
         this.b.seek((long) (i * 4096));
-        this.writeIntAndByte(j + 1, (byte)2); // Paper - Avoid 4 io write calls
+        this.writeIntAndByte(j + 1, (byte)PaperConfig.compressionMethod); // Paper - Avoid 4 io write calls // Paper - new compression support
         this.b.write(abyte, 0, j);
     }
 
@@ -487,18 +556,50 @@ public class RegionFile implements AutoCloseable {
 
     void writeOversizedData(int x, int z, NBTTagCompound oversizedData) throws IOException {
         File file = getOversizedFile(x, z);
-        try (DataOutputStream out = new DataOutputStream(new BufferedOutputStream(new DeflaterOutputStream(new java.io.FileOutputStream(file), new java.util.zip.Deflater(java.util.zip.Deflater.BEST_COMPRESSION), 32 * 1024), 32 * 1024))) {
-            NBTCompressedStreamTools.writeNBT(oversizedData, out);
+        // Paper start - new compression support
+        if (PaperConfig.compressionMethod == 127) {
+            try (DataOutputStream out = new DataOutputStream(new BufferedOutputStream(PaperConfig.zstdUseHighCompression ? new com.github.luben.zstd.ZstdOutputStream(new java.io.FileOutputStream(file), 15) : new com.github.luben.zstd.ZstdOutputStream(new java.io.FileOutputStream(file)), 32 * 1024))) {
+                NBTCompressedStreamTools.writeNBT(oversizedData, out);
+            }
+        } else if (PaperConfig.compressionMethod == 126) {
+            try (DataOutputStream out = new DataOutputStream(new BufferedOutputStream(new net.jpountz.lz4.LZ4FrameOutputStream(new java.io.FileOutputStream(file)), 32 * 1024))) {
+                NBTCompressedStreamTools.writeNBT(oversizedData, out);
+            }
+        } else if (PaperConfig.compressionMethod == 2) {
+            try (DataOutputStream out = new DataOutputStream(new BufferedOutputStream(new DeflaterOutputStream(new java.io.FileOutputStream(file), new java.util.zip.Deflater(java.util.zip.Deflater.BEST_COMPRESSION), 32 * 1024), 32 * 1024))) {
+                NBTCompressedStreamTools.writeNBT(oversizedData, out);
+            }
+        } else {
+            try (DataOutputStream out = new DataOutputStream(new BufferedOutputStream(new java.util.zip.GZIPOutputStream(new java.io.FileOutputStream(file)), 32 * 1024))) {
+                NBTCompressedStreamTools.writeNBT(oversizedData, out);
+            }
         }
+        // Paper end
         this.setOversized(x, z, true);
 
     }
 
     synchronized NBTTagCompound getOversizedData(int x, int z) throws IOException {
         File file = getOversizedFile(x, z);
-        try (DataInputStream out = new DataInputStream(new BufferedInputStream(new InflaterInputStream(new java.io.FileInputStream(file))))) {
-            return NBTCompressedStreamTools.readNBT(out);
+        // Paper start - new compression support
+        if (PaperConfig.compressionMethod == 127) {
+            try (DataInputStream out = new DataInputStream(new BufferedInputStream(new com.github.luben.zstd.ZstdInputStream(new java.io.FileInputStream(file))))) {
+                return NBTCompressedStreamTools.readNBT(out);
+            }
+        } else if (PaperConfig.compressionMethod == 126) {
+            try (DataInputStream out = new DataInputStream(new BufferedInputStream(new net.jpountz.lz4.LZ4FrameInputStream(new java.io.FileInputStream(file))))) {
+                return NBTCompressedStreamTools.readNBT(out);
+            }
+        } else if (PaperConfig.compressionMethod == 2) {
+            try (DataInputStream out = new DataInputStream(new BufferedInputStream(new InflaterInputStream(new java.io.FileInputStream(file))))) {
+                return NBTCompressedStreamTools.readNBT(out);
+            }
+        } else {
+            try (DataInputStream out = new DataInputStream(new BufferedInputStream(new GZIPInputStream(new java.io.FileInputStream(file))))) {
+                return NBTCompressedStreamTools.readNBT(out);
+            }
         }
+        // Paper end
 
     }
 
@@ -509,6 +610,16 @@ public class RegionFile implements AutoCloseable {
             org.bukkit.Bukkit.getLogger().log(java.util.logging.Level.SEVERE, "Using Spigot Oversized Chunk save method. Warning this will result in extremely fragmented chunks, as well as making the entire region file unable to be to used in any other software but Forge or Spigot (not usable in Vanilla or CraftBukkit). Paper's method is highly recommended.");
             org.bukkit.Bukkit.getLogger().log(java.util.logging.Level.SEVERE, "====================================");
         }
+
+        if (PaperConfig.compressionMethod == 127) {
+            System.out.println("Using zstd compression.");
+        } else if (PaperConfig.compressionMethod == 126) {
+            System.out.println("Using LZ4 compression.");
+        } else if (PaperConfig.compressionMethod == 2) {
+            System.out.println("Using zlib compression.");
+        } else {
+            System.out.println("Using GZIP compression.");
+        }
     }
     public class ChunkTooLargeException extends RuntimeException {
         public ChunkTooLargeException(int x, int z, int sectors) {
@@ -543,6 +654,7 @@ public class RegionFile implements AutoCloseable {
             // Paper start - apply dynamic compression
             int origLength = this.count;
             byte[] buf = this.buf;
+            System.out.println("Compressing chunk at " + this.b.x + ", " + this.b.z);
             DirectByteArrayOutputStream out = compressData(buf, origLength);
             byte[] bytes = out.getBuffer();
             int length = out.size();
@@ -555,18 +667,76 @@ public class RegionFile implements AutoCloseable {
     private static final java.util.zip.Deflater deflater = new java.util.zip.Deflater();
     // since file IO is single threaded, no benefit to using per-region file buffers/synchronization, we can change that later if it becomes viable.
     private static DirectByteArrayOutputStream compressData(byte[] buf, int length) throws IOException {
-        synchronized (deflater) {
-            deflater.setInput(buf, 0, length);
-            deflater.finish();
+        // Paper start - new compression support
+        if (PaperConfig.compressionMethod == 127) {
+            DirectByteArrayOutputStream out = new DirectByteArrayOutputStream(length);
 
+            long start = System.nanoTime();
+            try (com.github.luben.zstd.ZstdOutputStream compressedOut = PaperConfig.zstdUseHighCompression ? new com.github.luben.zstd.ZstdOutputStream(out, 15) : new com.github.luben.zstd.ZstdOutputStream(out)) {
+                compressedOut.write(buf);
+            }
+            out.close();
+            long finish = System.nanoTime();
+            System.out.println("Compression time: " + ((finish - start) / 1_000L) + "us");
+
+            if (out.size() > 0) {
+                System.out.println("Compression ratio: " + ((double) buf.length / (double) out.size()));
+            }
+            return out;
+        } else if (PaperConfig.compressionMethod == 126) {
             DirectByteArrayOutputStream out = new DirectByteArrayOutputStream(length);
-            while (!deflater.finished()) {
-                out.write(compressionBuffer, 0, deflater.deflate(compressionBuffer));
+
+            long start = System.nanoTime();
+            try (net.jpountz.lz4.LZ4FrameOutputStream compressedOut = new net.jpountz.lz4.LZ4FrameOutputStream(out)) {
+                compressedOut.write(buf);
             }
             out.close();
-            deflater.reset();
+            long finish = System.nanoTime();
+            System.out.println("Compression time: " + ((finish - start) / 1_000L) + "us");
+
+            if (out.size() > 0) {
+                System.out.println("Compression ratio: " + ((double) buf.length / (double) out.size()));
+            }
+            return out;
+        } else if (PaperConfig.compressionMethod == 2) {
+            synchronized (deflater) {
+                DirectByteArrayOutputStream out = new DirectByteArrayOutputStream(length);
+
+                long start = System.nanoTime();
+                deflater.setInput(buf, 0, length);
+                deflater.finish();
+
+                while (!deflater.finished()) {
+                    out.write(compressionBuffer, 0, deflater.deflate(compressionBuffer));
+                }
+                out.close();
+                deflater.reset();
+                long finish = System.nanoTime();
+                System.out.println("Compression time: " + ((finish - start) / 1_000L) + "us");
+
+                if (out.size() > 0) {
+                    System.out.println("Compression ratio: " + ((double) buf.length / (double) out.size()));
+                }
+                return out;
+            }
+        } else {
+            DirectByteArrayOutputStream out = new DirectByteArrayOutputStream(length);
+
+            long start = System.nanoTime();
+            try (java.util.zip.GZIPOutputStream compressedOut = new java.util.zip.GZIPOutputStream(out)) {
+                compressedOut.write(buf);
+            }
+
+            out.close();
+            long finish = System.nanoTime();
+            System.out.println("Compression time: " + ((finish - start) / 1_000L) + "us");
+
+            if (out.size() > 0) {
+                System.out.println("Compression ratio: " + ((double) buf.length / (double) out.size()));
+            }
             return out;
         }
+        // Paper end
     }
     // Paper end
 
-- 
2.22.0.windows.1

